% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/fit.R
\name{ud_fit}
\alias{ud_fit}
\alias{ud_fit_control_default}
\title{Fit Ultimate Deconvolution Model}
\usage{
ud_fit(fit, X, control = list(), verbose = TRUE)

ud_fit_control_default()
}
\arguments{
\item{fit}{A previous Ultimate Deconvolution model fit. Typically,
this will be an output of \code{\link{ud_init}} or an output
from a previous call to \code{ud_fit}.}

\item{X}{Optional n x m data matrix, in which each row of the matrix is
an m-dimensional data point. The number of rows and columns should
be 2 or more. When not provided, \code{fit$X} is used.}

\item{control}{A list of parameters controlling the behaviour of
the model fitting and initialization. See \sQuote{Details}.}

\item{verbose}{When \code{verbose = TRUE}, information about the
algorithm's progress is printed to the console at each
iteration. For interpretation of the columns, see the description
of the \code{progress} return value.}
}
\value{
An Ultimate Deconvolution model fit. It is a list object
with the following elements:

\item{X}{The data matrix used to fix the model.}

\item{w}{A vector containing the estimated mixture weights in the
  mixture-of-normals prior.}

\item{U}{A list containing the estimated prior covariance matrices.}

\item{V}{The estimated residual covariance matrix, or a list of
  fixed covariance matrices.}

\item{P}{The responsibilities matrix in which \code{P[i,j]} is the
  posterior mixture probability for data point i and mixture
  component j.}
 
\item{loglik}{The log-likelihood at the current settings of the
  model parameters.}
  
\item{progress}{A data frame containing detailed information about
  the algorithm's progress. The columns of the data frame are:
  "iter", the iteration number; "loglik", the log-likelihood at the
  current estimates of the model parameters; "delta.w", the largest
  change in the mixture weights; "delta.u", the largest change in the
  prior covariance matrices; "delta.v", the largest change in the
  residual covariance matrix; and "timing", the elapsed time in
  seconds (recorded using \code{\link{proc.time}}).}
}
\description{
This function implements "Ultimate Deconvolution", an
empirical Bayes method for fitting a multivariate normal means
model. This method is closely related to approaches for
multivariate density deconvolution (Sarkar \emph{et al}, 2018), so
it can also be viewed as a method for multivariate density
deconvolution.
}
\details{
In the Ultimate Deconvolution (UD) model, the
m-dimensional observation \eqn{x} is drawn from a mixture of
multivariate normals, \eqn{x ~ w_1 N(0, T_1) + ... + w_k N(0,
T_k)}, where \eqn{k \ge 2} is the number of mixture components,
the \eqn{w_j}'s are mixture weights, and each \eqn{T_j = V_j + U_j}
is a covariance matrix. This is the marginal density derived from a
model in which \eqn{x} is multivariate normal with mean \eqn{y} and
covariance \eqn{V}, and the underlying, or "latent", signal \eqn{y}
is in turn modeled by a mixture prior in which each mixture
component \eqn{j} is multivariate normal with zero mean and
covariance matrix \eqn{U_j}. This model is a useful special case of
the "Extreme Deconvolution" (ED) model (Bovy \emph{et al}, 2011),
and is closely related to the factor analysis model (Rubin and
Thayer, 1982).

Two variants of the UD model are implemented: one in which the
residual covariance V is the same for all data points, and another
in which V is different for each data point. In the first case,
V may be estimated.

The UD model is fit by an expectation-maximization (EM)
algorithm. The \code{control} argument can be used to adjust the EM
settings. It is a list in which any of the following named components
will override the default algorithm settings (as they are defined
by \code{ud_fit_control_default}):

\describe{

\item{\code{weights.update}}{When \code{weights.update = "em"}, the
mixture weights are updated via EM; when \code{weights.update =
"none"}, the mixture weights are not updated.}

\item{\code{resid.update}}{When \code{resid.update = "em"}, the
residual covariance matrix is updated via EM; when
\code{resid.update = "none"}, the residual covariance matrix is not
updated. When \code{resid.update = NA}, the update is determined by
V; if V is a matrix (that is, the case when the residual covariance
is the same for all data points), EM is used to update V; otherwise,
no updating is performed.}

\item{\code{scaled.update}}{This setting specifies the updates for
the scaled prior covariance matrices. Possible settings are
\code{"fa"}, \code{"none"} or \code{NA}.}

\item{\code{rank1.update}}{This setting specifies the updates for
the rank-1 prior covariance matrices. Possible settings are
\code{"ed"}, \code{"ted"}, \code{"none"} or \code{NA}.}

\item{\code{unconstrained.update}}{This setting determines the
updates used to estimate the unconstrained prior covariance
matrices. Two variants of EM are implemented: \code{update.U =
"ed"}, the EM updates described by Bovy \emph{et al} (2011); and
\code{update.U = "ted"}, "truncated eigenvalue decomposition", in
which the M-step update for each covariance matrix \code{U[[j]]} is
solved by truncating the eigenvalues in a spectral decomposition of
the unconstrained maximimum likelihood estimate (MLE) of
\code{U[j]]}. Other possible settings include \code{"none"} or
code{NA}.}

\item{\code{version}}{R and C++ implementations of the model
fitting algorithm are provided; these are selected with
\code{version = "R"} and \code{version = "Rcpp"}.}

\item{\code{maxiter}}{The upper limit on the number of updates
to perform.}

\item{\code{tol}}{The updates are halted when the largest change in
the model parameters between two successive updates is less than
\code{tol}.}

\item{\code{tol.lik}}{The updates are halted when the change in
increase in the likelihood between two successive iterations is
less than \code{tol.lik}.}

\item{\code{minval}}{Minimum eigenvalue allowed in the residual
covariance(s) \code{V} and the prior covariance matrices
\code{U}. Should be a small, positive number.}}

Using this function requires some care; currently only minimal
argument checking is performed. See the documentation and examples
for guidance.
}
\examples{
# Simulate data from a UD model.
set.seed(1)
n <- 4000
V <- rbind(c(0.8,0.2),
           c(0.2,1.5))
U <- list(none   = rbind(c(0,0),
                         c(0,0)),
          shared = rbind(c(1.0,0.9),
                         c(0.9,1.0)),
          only1  = rbind(c(1,0),
                         c(0,0)),
          only2  = rbind(c(0,0),
                         c(0,1)))
w <- c(0.8,0.1,0.075,0.025)
rownames(V) <- c("d1","d2")
colnames(V) <- c("d1","d2")
X <- simulate_ud_data(n,w,U,V)

# This is the simplest invocation of ud_init.
fit1 <- ud_init(X)
fit1 <- ud_fit(fit1)
logLik(fit1)
summary(fit1)
plot(fit1$progress$iter,
     max(fit1$progress$loglik) - fit1$progress$loglik + 0.1,
     type = "l",col = "dodgerblue",lwd = 2,log = "y",xlab = "iteration",
     ylab = "dist to best loglik")

# This is a more complex invocation of ud_init that overrides some
# of the defaults.
fit2 <- ud_init(X,U_scaled = U,n_rank1 = 1,n_unconstrained = 1,V = V)
fit2 <- ud_fit(fit2)
logLik(fit2)
summary(fit2)
plot(fit2$progress$iter,
     max(fit2$progress$loglik) - fit2$progress$loglik + 0.1,
     type = "l",col = "dodgerblue",lwd = 2,log = "y",xlab = "iteration",
     ylab = "dist to best loglik")

}
\references{
J. Bovy, D. W. Hogg and S. T. Roweis (2011). Extreme Deconvolution:
inferring complete distribution functions from noisy, heterogeneous
and incomplete observations. \emph{Annals of Applied Statistics},
\bold{5}, 1657–1677. doi:10.1214/10-AOAS439

D. B. Rubin and D. T. Thayer (1982). EM algorithms for ML factor
analysis. Psychometrika \bold{47}, 69-76. doi:10.1007/BF02293851

A. Sarkar, D. Pati, A. Chakraborty, B. K. Mallick and R. J. Carroll
(2018). Bayesian semiparametric multivariate density deconvolution.
\emph{Journal of the American Statistical Association} \bold{113},
401–416. doi:10.1080/01621459.2016.1260467

J. Won, J. Lim, S. Kim and B. Rajaratnam (2013).
Condition-number-regularized covariance estimation. \emph{Journal
of the Royal Statistical Society, Series B} \bold{75},
427–450. doi:10.1111/j.1467-9868.2012.01049.x
}
